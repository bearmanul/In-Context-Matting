## Deep Image Matting 笔记
动机：   
 传统的Matting算法只利用了图片的颜色、像素位置这种低级的特征，没有充分发挥纹理、语义等高级特征的作用，本文通过神经网络来对图像的高级特征进行学习，进一步进行抠图任务。

方法总结：  
该方法主要是用于求解图像的alpha matte。文章中的网络分为俩级，第一级是编码器-解码器网络，用于抽取图像的特征（低级和高级），输入图像的RGB以及trimap，通过编码器中卷积和池化层以及解码器中上采样和卷积层的作用，输出粗略的alpha matte。第二级网络则是对第一级网络输出的alpha matte进行微调，输入原图像RGB三通道以及第一级网络输出的alpha matte，通过卷积层以及残差连接的作用，最终输出更准确的alpha matte。
————————————————
### 网络结构
       网络分为俩阶段，第一个阶段是编码器、解码器结构，输入图片的RGB三通道以及trimap，输出略粗略的alpha matte，loss由alpha matte loss 和composition loss组成，第二个是refine阶段，输入RGB三通道和第一阶段输出的alpha matte四个通道的特征，通过卷积和残差shortcut连接获得Refined alpha matte，为最终的输出。整个网络的本质就是在学trimap中（128位置中）的具体alphamatte。
第一阶段：编码层由14个卷积层和5个池化层构成，解码器由五个上采样和七个卷积层构成。第一阶段使用了alpha loss 和 composition loss的组合：
Alphaloss：真实alpha matte和第一阶段预测alpha matte的loss：
![alt text](1953d0c0172ef9fd2bc79297c31d350f_413195a1e7494225130ef2a71e9fc281.png)

（2）Alpha matte(Alpha 混合、前景蒙版)
前景蒙版（alpha matte）：也称前景透明度或透明度蒙版，是前背景分离的结果，是一个灰度图，每一个像素点的灰度值表示原始图像每个像素属于前景物体的程度，白色代表某一个像素确定属于前景，黑色代表某一个像素确定属于背景。

（3）Alpha matte和Mask的区别
可以这么说，Mask是Matte的一种特例。在Mask里，只有两种透明度，1和0，即完全透明和完全不透明。Mask的产生是为了去除合成时的锯齿而设计的，但锯齿没了，不过合成痕迹太明显，显得很不真实。而Matte则可以包含很多层次的透明度，图像中每个像素都可以有自己的透明度，这些像素的透明度有着丰富的层级，可以合成、融合。
根据给出的验证结果，以下是每个指标的解释：

- `val/known_l1_loss`: 已知区域的 L1 损失值。
- `val/known_l1_loss_epoch`: 已知区域的平均 L1 损失值（整个验证集上）。
- `val/loss`: 总体损失值。
- `val/loss_epoch`: 平均总体损失值（整个验证集上）。
- `val/loss_gradient_penalty`: 梯度惩罚项的损失值。
- `val/loss_gradient_penalty_epoch`: 平均梯度惩罚项的损失值（整个验证集上）。
- `val/loss_pha_laplacian`: alpha 图像的拉普拉斯损失值。
- `val/loss_pha_laplacian_epoch`: 平均 alpha 图像的拉普拉斯损失值（整个验证集上）。
- `val/unknown_l1_loss`: 不确定区域的 L1 损失值。
- `val/unknown_l1_loss_epoch`: 不确定区域的平均 L1 损失值（整个验证集上）。

这些指标用于评估模型在验证集上的性能。L1 损失是预测值与目标值之间的绝对差异的平均值。梯度惩罚项是用于鼓励模型生成平滑输出的正则化项。拉普拉斯损失衡量 alpha 图像的平滑度。已知区域和不确定区域的损失值分别表示模型对已知区域和不确定区域的预测准确性。

要实现将 Alpha Matte 分成确定区域和不确定区域，并对这两类区域分别处理的操作，可以考虑以下步骤：

1. **数据预处理阶段** (`data_generator.py` 或相关数据加载文件):
   - 在数据加载和预处理阶段，您可以添加逻辑来识别和标记 Alpha Matte 中的确定区域和不确定区域。这可能涉及到修改 `DataGenerator` 类或在数据加载过程中添加自定义的预处理步骤。

2. **模型架构设计** (`in_context_matting.py` 或模型定义文件):
   - 在模型架构中，您需要设计一个机制来处理这两类区域。这可能意味着在模型中添加额外的分支或层，用于分别处理确定区域和不确定区域。

3. **特征提取器** (`feature_extractor.py` 或相关特征提取代码):
   - 特征提取器可能需要调整以提取对这两类区域都有区分性的特征。这可能涉及到对现有网络结构的修改，或添加新的网络层来专门处理不确定区域。

4. **损失函数设计** (`matting_criterion.py` 或损失函数定义文件):
   - 损失函数需要能够对确定区域和不确定区域应用不同的权重或处理逻辑。您可以修改现有的损失计算函数，或添加新的损失函数来专门处理不确定区域。

5. **上下文解码器** (`in_context_decoder.py` 或相关解码逻辑):
   - 上下文解码器负责生成最终的 Alpha Matte 输出。您需要在解码器中实现逻辑，以便它能够接收来自特征提取器的特征，并根据确定区域和不确定区域的分类来生成最终的 Alpha Matte。

6. **注意力机制的应用** (`attention.py`):
   - 如果您决定使用注意力机制来增强模型对不确定区域的关注，可以在 `Attention` 类中实现或调整注意力逻辑，并在模型架构中集成这些注意力层。

7. **模型训练和评估** (`train.py`):
   - 在模型训练和评估过程中，确保您的训练循环和评估逻辑能够处理新的数据格式和模型输出。这可能涉及到修改训练器配置和评估脚本。

8. **后处理步骤**:
   - 在模型生成初步的 Alpha Matte 后，可能需要后处理步骤来细化预测结果，特别是在不确定区域。这可能包括使用形态学操作或图像修复技术。

9. **代码集成**:
   - 将上述所有改进集成到您的代码库中，并确保所有组件协同工作。这可能涉及到修改 `train.py` 和其他脚本，以适应新的模型架构和数据处理流程。

`alpha` matte 来源

1. **图像读取**：首先，从文件系统中读取包含 alpha matte 信息的图像文件。这通常是一个单通道的灰度图像，其中包含了透明区域的透明度信息。

   ```python
   alpha = cv2.imread(self.alpha[idx % self.fg_num], 0).astype(np.float32)/255
   ```

   这里，`cv2.imread` 函数用于读取图像，第一个参数是图像文件的路径，第二个参数 `0` 表示以灰度模式读取（这样会返回一个单通道图像）。

2. **数据增强**：在 `DataGenerator` 类的 `__call__` 方法中，可能对 alpha matte 应用了不同的数据增强操作，例如仿射变换、随机裁剪、色调调整等。

3. **合成操作**：在训练阶段，`_composite_fg` 方法可能会将两个前景图像的 alpha matte 进行合成，以增加数据多样性。

   ```python
   alpha_tmp = 1 - (1 - alpha) * (1 - alpha2)
   ```

4. **尺寸调整**：如果 alpha matte 的尺寸与前景图像或背景图像的尺寸不匹配，可能会使用 `cv2.resize` 方法对其进行尺寸调整，以确保所有图像尺寸一致。

   ```python
   alpha = cv2.resize(alpha, (w, h), interpolation=maybe_random_interp(cv2.INTER_NEAREST))
   ```

5. **转换为 Tensor**：在 `ToTensor` 类中，alpha matte 会被转换为 PyTorch Tensor，以便于在深度学习模型中使用。

   ```python
   alpha = np.expand_dims(alpha.astype(np.float32), axis=0)
   sample['alpha'] = torch.from_numpy(alpha)
   ```

6. **归一化**：在转换为 Tensor 的过程中，alpha matte 可能会被归一化到 `[0, 1]` 范围内，以便于模型处理。

在 `data_generator.py` 中，`alpha` matte 主要用于生成训练数据，以及在模型训练和评估过程中提供透明度信息。